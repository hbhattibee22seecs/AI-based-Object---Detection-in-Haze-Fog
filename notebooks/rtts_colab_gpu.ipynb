{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09bce046",
   "metadata": {},
   "source": [
    "# RTTS Training (Local Workspace)\n",
    "\n",
    "This notebook is designed to run **directly from this repository** (no `git clone`, no dataset downloads). It trains YOLOX on the RTTS dataset under `data/RTTS` and runs an inference sanity check that saves an image with bounding boxes.\n",
    "\n",
    "\n",
    "\n",
    "If you want GPU training, make sure you installed a **CUDA-enabled** PyTorch build and that `torch.cuda.is_available()` is `True` (see the next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61b602",
   "metadata": {},
   "source": [
    "## 1. Configure Environment (CPU / GPU)\n",
    "\n",
    "These cells:\n",
    "\n",
    "\n",
    "\n",
    "- Locate the local repo root.\n",
    "\n",
    "- Add `src/` to `PYTHONPATH` for in-notebook imports.\n",
    "\n",
    "- Set `YOLOX_DATADIR` to the local `data/` folder.\n",
    "\n",
    "- Verify whether PyTorch can see a CUDA GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae3452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 14 09:19:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Verify PyTorch + CUDA visibility (works in local VS Code notebooks too)\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"cuda available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Could not import torch.\")\n",
    "    print(\"       Install PyTorch (CPU or CUDA) and restart the kernel.\")\n",
    "    print(\"       Error:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589159a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano'...\n",
      "remote: Enumerating objects: 311, done.\u001b[K\n",
      "remote: Counting objects: 100% (311/311), done.\u001b[K\n",
      "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
      "remote: Total 311 (delta 40), reused 284 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (311/311), 34.01 MiB | 28.76 MiB/s, done.\n",
      "Resolving deltas: 100% (40/40), done.\n",
      "/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.3\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: opencv-python>=4.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.12.0.88)\n",
      "Collecting loguru>=0.7 (from -r requirements.txt (line 4))\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.66 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
      "Requirement already satisfied: cython>=3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: pycocotools>=2.0.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.10)\n",
      "Collecting thop>=0.1.1.post2209072238 (from -r requirements.txt (line 10))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.24.0+cu126)\n",
      "Collecting onnx>=1.14 (from -r requirements.txt (line 15))\n",
      "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting onnxruntime>=1.16 (from -r requirements.txt (line 16))\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (9.10.2.21)\n",
      "Collecting mlflow>=2.9 (from -r requirements.txt (line 21))\n",
      "  Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: pillow>=10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (11.3.0)\n",
      "Requirement already satisfied: scikit-image>=0.21 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (0.25.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->-r requirements.txt (line 13)) (3.5.0)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.14->-r requirements.txt (line 15)) (5.29.5)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.14->-r requirements.txt (line 15)) (0.5.4)\n",
      "Collecting coloredlogs (from onnxruntime>=1.16->-r requirements.txt (line 16))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16->-r requirements.txt (line 16)) (25.9.23)\n",
      "Collecting mlflow-skinny==3.7.0 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.7.0 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (1.17.2)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (43.0.3)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (2.2.2)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (18.1.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (1.16.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=2.9->-r requirements.txt (line 21)) (2.0.45)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (6.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (8.3.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (3.1.2)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading databricks_sdk-0.74.0-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.118.3)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (1.37.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.12.3)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (1.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.32.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.5.4)\n",
      "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.38.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.9->-r requirements.txt (line 21)) (1.3.10)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.0.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.43.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.48.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.9->-r requirements.txt (line 21)) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.9->-r requirements.txt (line 21)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.9->-r requirements.txt (line 21)) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=2.9->-r requirements.txt (line 21)) (3.1.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (4.9.1)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.9->-r requirements.txt (line 21))\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.58b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow>=2.9->-r requirements.txt (line 21)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow>=2.9->-r requirements.txt (line 21)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow>=2.9->-r requirements.txt (line 21)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow>=2.9->-r requirements.txt (line 21)) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.9->-r requirements.txt (line 21)) (3.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (4.12.0)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.7.0->mlflow>=2.9->-r requirements.txt (line 21)) (0.16.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21->-r requirements.txt (line 23)) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21->-r requirements.txt (line 23)) (2025.10.16)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21->-r requirements.txt (line 23)) (0.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow>=2.9->-r requirements.txt (line 21)) (2.23)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1->-r requirements.txt (line 13)) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16->-r requirements.txt (line 16))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m177.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m225.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m189.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.74.0-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.2/764.2 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Installing collected packages: huey, loguru, humanfriendly, gunicorn, graphql-core, onnx, graphql-relay, docker, coloredlogs, onnxruntime, graphene, Flask-CORS, databricks-sdk, thop, mlflow-tracing, mlflow-skinny, mlflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [mlflow]16/17\u001b[0m [mlflow]skinny]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-CORS-6.0.2 coloredlogs-15.0.1 databricks-sdk-0.74.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.5 humanfriendly-10.0 loguru-0.7.3 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0 onnx-1.20.0 onnxruntime-1.23.2 thop-0.1.1.post2209072238\n"
     ]
    }
   ],
   "source": [
    "# Configure local repo paths (NO cloning / downloading)\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for candidate in (start, *start.parents):\n",
    "        if (candidate / \"src\" / \"tools\" / \"train.py\").exists() and (candidate / \"requirements.txt\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate repo root. Open this notebook from inside the YOLOX repo, \"\n",
    "        \"or set your working directory to the repo root before running cells.\"\n",
    "    )\n",
    "\n",
    "\n",
    "REPO_DIR = find_repo_root(Path.cwd())\n",
    "SRC_DIR = REPO_DIR / \"src\"\n",
    "\n",
    "# Ensure in-notebook imports resolve `yolox.*`\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# Point YOLOX at local dataset folder\n",
    "DATA_ROOT = Path(os.environ.get(\"YOLOX_DATADIR\", str(REPO_DIR / \"data\"))).resolve()\n",
    "os.environ[\"YOLOX_DATADIR\"] = str(DATA_ROOT)\n",
    "\n",
    "print(\"REPO_DIR:\", REPO_DIR)\n",
    "print(\"SRC_DIR:\", SRC_DIR)\n",
    "print(\"YOLOX_DATADIR:\", os.environ[\"YOLOX_DATADIR\"])\n",
    "\n",
    "# Optional: install Python dependencies into the current kernel environment\n",
    "INSTALL_DEPS = False\n",
    "if INSTALL_DEPS:\n",
    "    import subprocess\n",
    "\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REPO_DIR / \"requirements.txt\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1232c0",
   "metadata": {},
   "source": [
    "## 2. Dataset (Local)\n",
    "\n",
    "This notebook expects RTTS to already exist at:\n",
    "\n",
    "\n",
    "\n",
    "- `data/RTTS/Annotations`\n",
    "\n",
    "- `data/RTTS/JPEGImages`\n",
    "\n",
    "- `data/RTTS/ImageSets`\n",
    "\n",
    "\n",
    "\n",
    "If you already have the dataset elsewhere, set `YOLOX_DATADIR` to that parent folder (the folder that contains `RTTS/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/content/data/RTTS.zip]\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of /content/data/RTTS.zip or\n",
      "        /content/data/RTTS.zip.zip, and cannot find /content/data/RTTS.zip.ZIP, period.\n",
      "RTTS dataset ready at /content/data/RTTS\n"
     ]
    }
   ],
   "source": [
    "# Verify local RTTS layout under YOLOX_DATADIR\n",
    "from pathlib import Path\n",
    "\n",
    "RTTS_DIR = Path(os.environ[\"YOLOX_DATADIR\"]) / \"RTTS\"\n",
    "required = [\"Annotations\", \"JPEGImages\", \"ImageSets\"]\n",
    "missing = [name for name in required if not (RTTS_DIR / name).exists()]\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"RTTS dataset not found (or incomplete).\\n\"\n",
    "        f\"Expected: {RTTS_DIR}\\\\{{Annotations,JPEGImages,ImageSets}}\\n\"\n",
    "        f\"Missing: {missing}\\n\\n\"\n",
    "        \"Fix by placing RTTS under `data/RTTS`, or set YOLOX_DATADIR to the folder that contains `RTTS/`.\"\n",
    "    )\n",
    "\n",
    "print(f\"RTTS dataset ready at: {RTTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano\n",
      "Annotation directory not found: /content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/data/RTTS/Annotations\n"
     ]
    }
   ],
   "source": [
    "# Run the RTTS sanity checker (class distribution, sample parsing)\n",
    "import sys\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!{sys.executable} src/Jetson_src/temp_inspect_rtts.py --refresh --limit 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b5b76",
   "metadata": {},
   "source": [
    "### Results Directory Setup\n",
    "\n",
    "Create a unified `results/` tree so plots, weights, and inference artifacts end up in one place. (Everything stays inside this repo folder.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be stored under /content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/results\n",
      "TensorBoard logs expected in /content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/YOLOX_outputs/rtts_yolox_s/tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Create shared results directories and handy path helpers\n",
    "from pathlib import Path\n",
    "\n",
    "RESULTS_DIR = REPO_DIR / \"results\"\n",
    "PLOTS_DIR = RESULTS_DIR / \"plots\"\n",
    "WEIGHTS_DIR = RESULTS_DIR / \"weights\"\n",
    "INFER_DIR = RESULTS_DIR / \"inference_samples\"\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "for path in (PLOTS_DIR, WEIGHTS_DIR, INFER_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXP_NAME = \"rtts_yolox_s\"\n",
    "OUTPUT_DIR = REPO_DIR / \"YOLOX_outputs\" / EXP_NAME\n",
    "BEST_CKPT = OUTPUT_DIR / \"best_ckpt.pth\"\n",
    "LATEST_CKPT = OUTPUT_DIR / \"latest_ckpt.pth\"\n",
    "TENSORBOARD_DIR = OUTPUT_DIR / \"tensorboard\"\n",
    "\n",
    "print(f\"Results will be stored under {RESULTS_DIR}\")\n",
    "print(f\"YOLOX output dir: {OUTPUT_DIR}\")\n",
    "print(f\"TensorBoard logs expected in {TENSORBOARD_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc62f3",
   "metadata": {},
   "source": [
    "## 3. Build Model Architecture\n",
    "YOLOX supplies the RTTS-specific experiment in `src/exps/example/custom/rtts_yolox_s.py`. The next cell prints key hyperparameters so you can tweak depth/width, input resolution, or augmentation knobs before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5657717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\n",
      "# -*- coding:utf-8 -*-\n",
      "# Copyright (c) Megvii, Inc. and its affiliates.\n",
      "import os\n",
      "\n",
      "from yolox.data import RTTSDataset, TrainTransform, ValTransform, get_yolox_datadir\n",
      "from yolox.evaluators import VOCEvaluator\n",
      "from yolox.exp import Exp as MyExp\n",
      "\n",
      "\n",
      "class Exp(MyExp):\n",
      "    def __init__(self):\n",
      "        super(Exp, self).__init__()\n",
      "        self.depth = 0.33\n",
      "        self.width = 0.50\n",
      "        self.num_classes = 5\n",
      "        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n",
      "\n",
      "        rtts_root = os.path.join(get_yolox_datadir(), \"RTTS\")\n",
      "        self.data_dir = rtts_root\n",
      "        self.train_splits = (\"train\",)\n",
      "        self.val_splits = (\"val\",)\n",
      "        self.test_splits = (\"test\",)\n",
      "\n",
      "        self.max_epoch = 300\n",
      "        self.data_num_workers = 4\n",
      "        self.eval_interval = 1\n",
      "\n",
      "    def get_dataset(self, cache: bool = False, cache_type: str = \"ram\"):\n",
      "        return RTTSDataset(\n",
      "            data_dir=self.data_dir,\n",
      "            image_sets=self.train_splits,\n",
      "            img_size=self.input_size,\n",
      "            preproc=TrainTransform(\n",
      "                max_labels=50, flip_prob=self.flip_prob, hsv_prob=self.hsv_prob\n",
      "            ),\n",
      "            cache=cache,\n",
      "            cache_type=cache_type,\n",
      "        )\n",
      "\n",
      "    def get_eval_dataset(self, **kwargs):\n",
      "        legacy = kwargs.get(\"legacy\", False)\n",
      "        splits = self.test_splits if kwargs.get(\"testdev\", False) else self.val_splits\n",
      "        return RTTSDataset(\n",
      "            data_dir=self.data_dir,\n",
      "            image_sets=splits,\n",
      "            img_size=self.test_size,\n",
      "            preproc=ValTransform(legacy=legacy),\n",
      "        )\n",
      "\n",
      "    def get_evaluator(self, batch_size, is_distributed, testdev=False, legacy=False):\n",
      "        return VOCEvaluator(\n",
      "            dataloader=self.get_eval_loader(\n",
      "                batch_size, is_distributed, testdev=testdev, legacy=legacy\n",
      "            ),\n",
      "            img_size=self.test_size,\n",
      "            confthre=self.test_conf,\n",
      "            nmsthre=self.nmsthre,\n",
      "            num_classes=self.num_classes,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the core experiment settings for YOLOX-S on RTTS\n",
    "from pathlib import Path\n",
    "exp_path = REPO_DIR / \"src\" / \"exps\" / \"example\" / \"custom\" / \"rtts_yolox_s.py\"\n",
    "print(exp_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf841279",
   "metadata": {},
   "source": [
    "## 3. Train (uses local repo + local dataset)\n",
    "\n",
    "Training runs via `src/tools/train.py` and writes checkpoints/logs under `YOLOX_outputs/<EXP_NAME>/`.\n",
    "\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "- GPU is used automatically if `torch.cuda.is_available()` is `True`.\n",
    "\n",
    "- If you switch between CPU/GPU installs, restart the kernel.\n",
    "\n",
    "- For a quick end-to-end check, set `TRAIN_ITERS_PER_EPOCH = 50` to cap runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abbe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/src/Jetson_src/train_rtts.py\", line 152, in <module>\n",
      "    main()\n",
      "  File \"/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/src/Jetson_src/train_rtts.py\", line 130, in main\n",
      "    _verify_dataset(datadir)\n",
      "  File \"/content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/src/Jetson_src/train_rtts.py\", line 30, in _verify_dataset\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: RTTS dataset is incomplete. Expected files were not found:\n",
      "/content/data/RTTS/Annotations\n",
      "/content/data/RTTS/JPEGImages\n",
      "/content/data/RTTS/ImageSets/Main/train.txt\n"
     ]
    }
   ],
   "source": [
    "# Launch training\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    use_fp16 = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    use_fp16 = False\n",
    "\n",
    "TRAIN_ITERS_PER_EPOCH = 50  # set to 0 for full epoch\n",
    "MAX_EPOCH = 1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"src/tools/train.py\",\n",
    "    \"-f\",\n",
    "    \"src/exps/example/custom/rtts_yolox_s.py\",\n",
    "    \"-d\",\n",
    "    \"1\",\n",
    "    \"-b\",\n",
    "    str(BATCH_SIZE),\n",
    "    \"-c\",\n",
    "    \"src/yolox/weights/yolox_s.pth\",\n",
    "    \"-expn\",\n",
    "    EXP_NAME,\n",
    "    \"max_epoch\",\n",
    "    str(MAX_EPOCH),\n",
    "]\n",
    "\n",
    "# Optional: cap iterations for a fast smoke run\n",
    "if TRAIN_ITERS_PER_EPOCH and TRAIN_ITERS_PER_EPOCH > 0:\n",
    "    cmd += [\"train_iters_per_epoch\", str(TRAIN_ITERS_PER_EPOCH)]\n",
    "    # Skip evaluation during smoke runs\n",
    "    cmd += [\"eval_interval\", \"999999\"]\n",
    "\n",
    "# Mixed precision only makes sense on CUDA\n",
    "if use_fp16:\n",
    "    cmd += [\"--fp16\"]\n",
    "\n",
    "print(\"Running:\")\n",
    "print(\" \".join(cmd))\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "subprocess.check_call(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66558723",
   "metadata": {},
   "source": [
    "### Persist Checkpoints to `results/weights`\n",
    "Mirror the best and latest checkpoints into the shared results directory so they can be zipped or downloaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf5a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] /content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/YOLOX_outputs/rtts_yolox_s/best_ckpt.pth not found yet; re-run after training finishes.\n",
      "[WARN] /content/Object-Detection-in-Hazy-and-Foggy-Conditions-on-NVIDIA-Jetson-Nano/YOLOX_outputs/rtts_yolox_s/latest_ckpt.pth not found yet; re-run after training finishes.\n",
      "Total checkpoints mirrored: 0\n"
     ]
    }
   ],
   "source": [
    "# Copy checkpoints into results/weights for convenient download\n",
    "import shutil\n",
    "weights_copied = 0\n",
    "for ckpt in [BEST_CKPT, LATEST_CKPT]:\n",
    "    if ckpt.exists():\n",
    "        destination = WEIGHTS_DIR / ckpt.name\n",
    "        shutil.copy2(ckpt, destination)\n",
    "        weights_copied += 1\n",
    "        print(f\"Copied {ckpt.name} -> {destination}\")\n",
    "    else:\n",
    "        print(f\"[WARN] {ckpt} not found yet; re-run after training finishes.\")\n",
    "print(f\"Total checkpoints mirrored: {weights_copied}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0436d1",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Export Artifacts (Optional)\n",
    "\n",
    "After training completes you can:\n",
    "\n",
    "\n",
    "\n",
    "- Run evaluation on the validation split.\n",
    "\n",
    "- Export ONNX.\n",
    "\n",
    "- (Optional) Export TensorRT artifacts if CUDA + TensorRT are installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best checkpoint (optional)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    use_fp16 = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    use_fp16 = False\n",
    "\n",
    "if not BEST_CKPT.exists():\n",
    "    raise FileNotFoundError(f\"Best checkpoint not found yet: {BEST_CKPT}\")\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"src/tools/eval.py\",\n",
    "    \"-f\",\n",
    "    \"src/exps/example/custom/rtts_yolox_s.py\",\n",
    "    \"-c\",\n",
    "    str(BEST_CKPT),\n",
    "    \"-b\",\n",
    "    \"1\",\n",
    "    \"-d\",\n",
    "    \"1\",\n",
    "    \"--conf\",\n",
    "    \"0.001\",\n",
    "]\n",
    "if use_fp16:\n",
    "    cmd += [\"--fp16\"]\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "subprocess.check_call(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ONNX (CPU/GPU) and (optionally) TensorRT (GPU-only)\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "EXPORT_DIR = REPO_DIR / \"exports\"\n",
    "EXPORT_DIR.mkdir(exist_ok=True)\n",
    "ONNX_PATH = EXPORT_DIR / \"rtts_yolox_s.onnx\"\n",
    "\n",
    "if not BEST_CKPT.exists():\n",
    "    raise FileNotFoundError(f\"Best checkpoint not found yet: {BEST_CKPT}\")\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "\n",
    "subprocess.check_call(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"src/tools/export_onnx.py\",\n",
    "        \"-f\",\n",
    "        \"src/exps/example/custom/rtts_yolox_s.py\",\n",
    "        \"-c\",\n",
    "        str(BEST_CKPT),\n",
    "        \"--output-file\",\n",
    "        str(ONNX_PATH),\n",
    "        \"--input\",\n",
    "        \"[640,640]\",\n",
    "    ]\n",
    ")\n",
    "print(\"Exported ONNX to:\", ONNX_PATH)\n",
    "\n",
    "# TensorRT requires CUDA + TensorRT installed.\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    has_cuda = False\n",
    "\n",
    "if has_cuda:\n",
    "    TRT_ENGINE = EXPORT_DIR / \"rtts_yolox_s_fp16.trt\"\n",
    "    subprocess.check_call(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"src/tools/trt.py\",\n",
    "            \"-f\",\n",
    "            \"src/exps/example/custom/rtts_yolox_s.py\",\n",
    "            \"-c\",\n",
    "            str(BEST_CKPT),\n",
    "            \"--trt_fp16\",\n",
    "            \"--device\",\n",
    "            \"0\",\n",
    "            \"--output-name\",\n",
    "            str(TRT_ENGINE),\n",
    "        ]\n",
    "    )\n",
    "    print(\"Exported TensorRT engine to:\", TRT_ENGINE)\n",
    "else:\n",
    "    print(\"[INFO] Skipping TensorRT export (no CUDA visible).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f18f99",
   "metadata": {},
   "source": [
    "### Visualize Training & Validation Curves\n",
    "Use the TensorBoard event logs to chart training losses, learning rate, and validation AP. All plots are saved under `results/plots`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation curves from TensorBoard logs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "if not TENSORBOARD_DIR.exists():\n",
    "    raise FileNotFoundError(f\"TensorBoard directory not found: {TENSORBOARD_DIR}\")\n",
    "\n",
    "accumulator = EventAccumulator(str(TENSORBOARD_DIR))\n",
    "accumulator.Reload()\n",
    "scalar_tags = set(accumulator.Tags().get(\"scalars\", []))\n",
    "\n",
    "\n",
    "def load_series(tag: str) -> pd.DataFrame:\n",
    "    events = accumulator.Scalars(tag)\n",
    "    return pd.DataFrame({\n",
    "        \"step\": [event.step for event in events],\n",
    "        \"value\": [event.value for event in events],\n",
    "        \"tag\": tag,\n",
    "    })\n",
    "\n",
    "# Training losses\n",
    "train_tags = [\n",
    "    tag for tag in (\n",
    "        \"train/total_loss\",\n",
    "        \"train/iou_loss\",\n",
    "        \"train/conf_loss\",\n",
    "        \"train/cls_loss\",\n",
    "        \"train/lr\",\n",
    "    ) if tag in scalar_tags\n",
    "]\n",
    "\n",
    "figures = []\n",
    "if train_tags:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    for tag in train_tags:\n",
    "        series = load_series(tag)\n",
    "        label = tag.split(\"/\", 1)[1]\n",
    "        ax.plot(series[\"step\"], series[\"value\"], label=label)\n",
    "    ax.set_xlabel(\"iteration\")\n",
    "    ax.set_ylabel(\"value\")\n",
    "    ax.set_title(\"Training losses & LR\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    train_plot = PLOTS_DIR / \"train_curves.png\"\n",
    "    fig.savefig(train_plot, dpi=200)\n",
    "    figures.append(train_plot)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No train/* scalars in TensorBoard logs (did training finish?).\")\n",
    "\n",
    "# Validation AP curves\n",
    "val_tags = [tag for tag in (\"val/COCOAP50\", \"val/COCOAP50_95\") if tag in scalar_tags]\n",
    "if val_tags:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    for tag in val_tags:\n",
    "        series = load_series(tag)\n",
    "        label = tag.split(\"/\", 1)[1]\n",
    "        ax.plot(series[\"step\"], series[\"value\"], marker=\"o\", label=label)\n",
    "    ax.set_xlabel(\"epoch\")\n",
    "    ax.set_ylabel(\"AP\")\n",
    "    ax.set_title(\"Validation AP progression\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    fig.tight_layout()\n",
    "    val_plot = PLOTS_DIR / \"val_ap.png\"\n",
    "    fig.savefig(val_plot, dpi=200)\n",
    "    figures.append(val_plot)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No val/* scalars found; ensure eval_interval > 0 during training.\")\n",
    "\n",
    "print(\"Stored plots:\")\n",
    "for fig_path in figures:\n",
    "    print(\" -\", fig_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb22918",
   "metadata": {},
   "source": [
    "### Local Inference Smoke Test\n",
    "Run `tools/demo.py` on a representative RTTS image, copy the rendered result into `results/inference_samples`, and display it inline to verify the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick image inference and archive the rendered output\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Image as IPyImage, display\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "    use_fp16 = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    device = \"cpu\"\n",
    "    use_fp16 = False\n",
    "\n",
    "jpeg_root = RTTS_DIR / \"JPEGImages\"\n",
    "sample_candidates = sorted(list(jpeg_root.glob(\"*.png\"))) or sorted(list(jpeg_root.glob(\"*.jpg\")))\n",
    "if not sample_candidates:\n",
    "    raise FileNotFoundError(f\"No images found inside {jpeg_root}\")\n",
    "\n",
    "SAMPLE_IMAGE = sample_candidates[0]\n",
    "print(f\"Using sample image: {SAMPLE_IMAGE}\")\n",
    "\n",
    "ckpt_path = BEST_CKPT if BEST_CKPT.exists() else LATEST_CKPT\n",
    "if not ckpt_path.exists():\n",
    "    raise FileNotFoundError(f\"No checkpoint found at {BEST_CKPT} or {LATEST_CKPT}\")\n",
    "\n",
    "vis_root = OUTPUT_DIR / \"vis_res\"\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"src/tools/demo.py\",\n",
    "    \"image\",\n",
    "    \"-f\",\n",
    "    \"src/exps/example/custom/rtts_yolox_s.py\",\n",
    "    \"-c\",\n",
    "    str(ckpt_path),\n",
    "    \"--path\",\n",
    "    str(SAMPLE_IMAGE),\n",
    "    \"--conf\",\n",
    "    \"0.001\",\n",
    "    \"--nms\",\n",
    "    \"0.45\",\n",
    "    \"--device\",\n",
    "    device,\n",
    "    \"--save_result\",\n",
    "    \"-expn\",\n",
    "    EXP_NAME,\n",
    "]\n",
    "if use_fp16:\n",
    "    cmd += [\"--fp16\"]\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "subprocess.check_call(cmd)\n",
    "\n",
    "if not vis_root.exists():\n",
    "    raise FileNotFoundError(f\"No visualization directory found at {vis_root}\")\n",
    "latest_folder = max(vis_root.iterdir(), key=lambda d: d.stat().st_mtime)\n",
    "rendered = list(latest_folder.glob(SAMPLE_IMAGE.name)) or list(latest_folder.glob(\"*\"))\n",
    "if not rendered:\n",
    "    raise FileNotFoundError(f\"No rendered files found under {latest_folder}\")\n",
    "\n",
    "render_path = rendered[0]\n",
    "target = INFER_DIR / render_path.name\n",
    "shutil.copy2(render_path, target)\n",
    "print(f\"Copied rendered image to {target}\")\n",
    "display(IPyImage(filename=target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c38050",
   "metadata": {},
   "source": [
    "### Confusion Matrix on Validation Split\n",
    "Re-run evaluation inside this notebook, collect detections, and derive a confusion matrix (IoU ≥ 0.5) to spot which classes still confuse the model. Results are written to `results/plots/confusion_matrix.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed742f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a confusion matrix by matching predictions to ground truth at IoU >= 0.5\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from yolox.exp import get_exp\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "exp = get_exp(str(REPO_DIR / \"src\" / \"exps\" / \"example\" / \"custom\" / \"rtts_yolox_s.py\"), None)\n",
    "model = exp.get_model()\n",
    "ckpt = torch.load(BEST_CKPT, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "model.to(device).eval()\n",
    "\n",
    "evaluator = exp.get_evaluator(batch_size=1, is_distributed=False)\n",
    "(_, _, _), predictions = evaluator.evaluate(model, half=torch.cuda.is_available(), return_outputs=True)\n",
    "dataset = evaluator.dataloader.dataset\n",
    "class_names = list(getattr(dataset, \"_classes\", [f\"class_{i}\" for i in range(exp.num_classes)]))\n",
    "labels = class_names + [\"background\"]\n",
    "mat = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "iou_thresh = 0.5\n",
    "max_images = min(len(predictions), 400)\n",
    "\n",
    "\n",
    "def iou(box, boxes):\n",
    "    if boxes.size == 0:\n",
    "        return np.array([])\n",
    "    box = np.expand_dims(box, axis=0)\n",
    "    lt = np.maximum(box[..., :2], boxes[..., :2])\n",
    "    rb = np.minimum(box[..., 2:], boxes[..., 2:])\n",
    "    wh = np.clip(rb - lt, a_min=0, a_max=None)\n",
    "    inter = wh[..., 0] * wh[..., 1]\n",
    "    box_area = (box[..., 2] - box[..., 0]) * (box[..., 3] - box[..., 1])\n",
    "    boxes_area = (boxes[..., 2] - boxes[..., 0]) * (boxes[..., 3] - boxes[..., 1])\n",
    "    union = box_area + boxes_area - inter\n",
    "    return inter / np.clip(union, a_min=1e-6, a_max=None)\n",
    "\n",
    "\n",
    "def to_numpy(pred_tuple):\n",
    "    if pred_tuple[0] is None:\n",
    "        return np.zeros((0, 4)), np.zeros((0,), dtype=int), np.zeros((0,))\n",
    "    boxes, cls, scores = pred_tuple\n",
    "    return boxes.numpy(), cls.numpy().astype(int), scores.numpy()\n",
    "\n",
    "\n",
    "processed = 0\n",
    "for img_id in sorted(predictions.keys()):\n",
    "    if processed >= max_images:\n",
    "        break\n",
    "    pred_boxes, pred_cls, pred_scores = to_numpy(predictions[img_id])\n",
    "    gt = dataset.annotations[img_id][0] if len(dataset.annotations) > img_id else np.zeros((0, 5))\n",
    "    gt_boxes = gt[:, :4] if gt.size else np.zeros((0, 4))\n",
    "    gt_cls = gt[:, 4].astype(int) if gt.size else np.zeros((0,), dtype=int)\n",
    "\n",
    "    order = np.argsort(-pred_scores)\n",
    "    pred_boxes, pred_cls, pred_scores = pred_boxes[order], pred_cls[order], pred_scores[order]\n",
    "    matched_gt = set()\n",
    "\n",
    "    for p_box, p_cls in zip(pred_boxes, pred_cls):\n",
    "        if gt_boxes.size:\n",
    "            ious = iou(p_box, gt_boxes)\n",
    "            best_idx = int(np.argmax(ious)) if ious.size else -1\n",
    "            best_iou = ious[best_idx] if ious.size else 0.0\n",
    "        else:\n",
    "            best_idx, best_iou = -1, 0.0\n",
    "\n",
    "        if best_idx >= 0 and best_iou >= iou_thresh and best_idx not in matched_gt:\n",
    "            gt_label = gt_cls[best_idx]\n",
    "            mat[gt_label, p_cls] += 1\n",
    "            matched_gt.add(best_idx)\n",
    "        else:\n",
    "            mat[len(class_names), p_cls] += 1  # false positives counted in last row\n",
    "\n",
    "    for gt_idx, gt_label in enumerate(gt_cls):\n",
    "        if gt_idx not in matched_gt:\n",
    "            mat[gt_label, len(class_names)] += 1  # misses counted in last column\n",
    "\n",
    "    processed += 1\n",
    "\n",
    "print(f\"Confusion stats built from {processed} validation images\")\n",
    "cm_path = PLOTS_DIR / \"confusion_matrix.png\"\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(mat, cmap=\"Blues\")\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_yticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel(\"Predicted class\")\n",
    "ax.set_ylabel(\"Ground truth class\")\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "fig.tight_layout()\n",
    "fig.savefig(cm_path, dpi=220)\n",
    "plt.show()\n",
    "print(f\"Confusion matrix saved to {cm_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9176e5",
   "metadata": {},
   "source": [
    "## 6. Package Jetson Nano Inference Script\n",
    "Jetson-friendly inference uses TensorRT plus lightweight preprocessing. The cell below emits `src/Jetson_src/jetson_nano_runner.py`, which loads the exported ONNX/TensorRT engine, runs warmup, and exposes CLI switches for images, video files, or live cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Jetson Nano inference helper script\n",
    "from textwrap import dedent\n",
    "\n",
    "script_path = REPO_DIR / \"src\" / \"Jetson_src\" / \"jetson_nano_runner.py\"\n",
    "script_path.write_text(dedent('''#!/usr/bin/env python3\n",
    "\"\"\"TensorRT-friendly inference helper tailored for Jetson Nano.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "ROOT = Path(__file__).resolve().parents[2]\n",
    "DEFAULT_EXP = ROOT / \"src\" / \"exps\" / \"example\" / \"custom\" / \"rtts_yolox_s.py\"\n",
    "DEFAULT_EXP_NAME = \"rtts_yolox_s\"\n",
    "DEFAULT_CKPT = ROOT / \"YOLOX_outputs\" / DEFAULT_EXP_NAME / \"best_ckpt.pth\"\n",
    "DEFAULT_TRT = ROOT / \"YOLOX_outputs\" / DEFAULT_EXP_NAME / \"model_trt.pth\"\n",
    "DEMO_SCRIPT = ROOT / \"src\" / \"tools\" / \"demo.py\"\n",
    "\n",
    "\n",
    "def _run(cmd: List[str]) -> None:\n",
    "    print(\"[jetson_nano_runner]\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True, cwd=ROOT)\n",
    "\n",
    "\n",
    "def _ensure_trt(args: argparse.Namespace) -> None:\n",
    "    if args.trt_file.exists() and not args.rebuild:\n",
    "        print(f\"[jetson_nano_runner] Reusing TensorRT weights at {args.trt_file}\")\n",
    "        return\n",
    "\n",
    "    build_cmd = [\n",
    "        \"python3\",\n",
    "        \"src/tools/trt.py\",\n",
    "        \"-f\",\n",
    "        str(args.exp),\n",
    "        \"-c\",\n",
    "        str(args.ckpt),\n",
    "        \"-expn\",\n",
    "        args.exp_name,\n",
    "    ]\n",
    "    _run(build_cmd)\n",
    "\n",
    "    built_file = ROOT / \"YOLOX_outputs\" / args.exp_name / \"model_trt.pth\"\n",
    "    if not built_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"TensorRT conversion did not produce {built_file}. Check tools/trt.py logs.\"\n",
    "        )\n",
    "    args.trt_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(built_file, args.trt_file)\n",
    "    print(f\"[jetson_nano_runner] Copied TensorRT weights to {args.trt_file}\")\n",
    "\n",
    "\n",
    "def _launch_demo(args: argparse.Namespace) -> None:\n",
    "    cmd = [\n",
    "        \"python3\",\n",
    "        str(DEMO_SCRIPT),\n",
    "        args.mode,\n",
    "        \"-f\",\n",
    "        str(args.exp),\n",
    "        \"--device\",\n",
    "        \"gpu\",\n",
    "        \"--conf\",\n",
    "        str(args.conf),\n",
    "        \"--nms\",\n",
    "        str(args.nms),\n",
    "        \"--trt\",\n",
    "        \"--trt-file\",\n",
    "        str(args.trt_file),\n",
    "        \"--save_result\",\n",
    "    ]\n",
    "    if args.fp16:\n",
    "        cmd.append(\"--fp16\")\n",
    "    if args.tsize:\n",
    "        cmd.extend([\"--tsize\", str(args.tsize)])\n",
    "\n",
    "    if args.mode in {\"image\", \"video\"}:\n",
    "        cmd.extend([\"--path\", str(args.input)])\n",
    "    else:\n",
    "        cmd.extend([\"--camid\", str(args.cam_id)])\n",
    "\n",
    "    _run(cmd)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\"--exp\", type=Path, default=DEFAULT_EXP, help=\"Experiment file\")\n",
    "    parser.add_argument(\"--exp-name\", default=DEFAULT_EXP_NAME, help=\"Experiment/output name\")\n",
    "    parser.add_argument(\"--ckpt\", type=Path, default=DEFAULT_CKPT, help=\"Checkpoint path\")\n",
    "    parser.add_argument(\"--trt-file\", type=Path, default=DEFAULT_TRT, help=\"TensorRT weight file\")\n",
    "    parser.add_argument(\"--mode\", choices=[\"image\", \"video\", \"webcam\"], default=\"image\")\n",
    "    parser.add_argument(\"--input\", type=Path,\n",
    "                        default=ROOT / \"data\" / \"RTTS\" / \"JPEGImages\" / \"AM_Bing_211.png\")\n",
    "    parser.add_argument(\"--cam-id\", type=int, default=0)\n",
    "    parser.add_argument(\"--conf\", type=float, default=0.25)\n",
    "    parser.add_argument(\"--nms\", type=float, default=0.45)\n",
    "    parser.add_argument(\"--tsize\", type=int, default=640, help=\"Square inference size\")\n",
    "    parser.add_argument(\"--datadir\", type=Path, default=ROOT / \"data\")\n",
    "    parser.add_argument(\"--rebuild\", action=\"store_true\", help=\"Force TensorRT rebuild\")\n",
    "    parser.add_argument(\"--skip-build\", action=\"store_true\", help=\"Skip TensorRT conversion\")\n",
    "    parser.add_argument(\"--fp16\", action=\"store_true\", help=\"Enable FP16 inference\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    os.environ.setdefault(\"YOLOX_DATADIR\", str(args.datadir.resolve()))\n",
    "\n",
    "    if not args.skip_build:\n",
    "        _ensure_trt(args)\n",
    "\n",
    "    _launch_demo(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''))\n",
    "script_path.chmod(0o755)\n",
    "print(f\"Jetson Nano runner created at {script_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45083ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle key artifacts (results, exports, scripts) into a single zip for download\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "BUNDLE_NAME = \"rtts_yolox_s_artifacts.zip\"\n",
    "BUNDLE_PATH = RESULTS_DIR / BUNDLE_NAME\n",
    "if BUNDLE_PATH.exists():\n",
    "    BUNDLE_PATH.unlink()\n",
    "\n",
    "paths_to_package = [\n",
    "    RESULTS_DIR,\n",
    "    EXPORT_DIR,\n",
    "    REPO_DIR / \"src\" / \"exps\" / \"example\" / \"custom\" / \"rtts_yolox_s.py\",\n",
    "    REPO_DIR / \"src\" / \"Jetson_src\" / \"jetson_nano_runner.py\",\n",
    "]\n",
    "\n",
    "files_to_add = []\n",
    "for path in paths_to_package:\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        print(f\"[WARN] Skipping missing path: {path}\")\n",
    "        continue\n",
    "    if path.is_dir():\n",
    "        files_to_add.extend([p for p in path.rglob(\"*\") if p.is_file()])\n",
    "    else:\n",
    "        files_to_add.append(path)\n",
    "\n",
    "with zipfile.ZipFile(BUNDLE_PATH, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    for file_path in files_to_add:\n",
    "        if file_path.resolve() == BUNDLE_PATH.resolve():\n",
    "            continue\n",
    "        arcname = file_path.relative_to(REPO_DIR)\n",
    "        zf.write(file_path, arcname)\n",
    "\n",
    "print(f\"Bundle ready at {BUNDLE_PATH} (contains {len(files_to_add)} files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d38419",
   "metadata": {},
   "source": [
    "## 5. Jetson Nano Notes (Optional)\n",
    "\n",
    "If you plan to deploy to Jetson Nano, use this as a starting checklist:\n",
    "\n",
    "\n",
    "\n",
    "1. **Flash & update Jetson Nano**: Install JetPack (includes CUDA/cuDNN/TensorRT).\n",
    "\n",
    "2. **Install Python deps**: create a venv, `pip3 install -r requirements.txt`, then install a PyTorch build appropriate for Jetson/JetPack.\n",
    "\n",
    "3. **Copy artifacts** produced above (checkpoints / exports) to the Jetson and keep the same `YOLOX_DATADIR` layout (a folder containing `RTTS/`).\n",
    "\n",
    "4. **(Optional) TensorRT rebuild**: run `python3 src/tools/trt.py ...` on-device if you need a native engine.\n",
    "\n",
    "5. **Run inference** with the helper script: `python3 src/Jetson_src/jetson_nano_runner.py --mode image --input data/RTTS/JPEGImages/AM_Bing_211.png ...`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
